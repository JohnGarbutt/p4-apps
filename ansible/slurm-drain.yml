---
- hosts: openstack
  gather_facts: false
  roles:
    - role: stackhpc.cluster-infra
      cluster_name: "{{ cluster_name }}"
      cluster_state: query
      cluster_params:
        cluster_groups: "{{ cluster_groups }}"
  tasks:
    - name: Count the number of compute nodes per slurm partition
      vars:
        partition: "{{ cluster_group.output_value | selectattr('group', 'equalto', item.name) | list }}"
      set_fact:
        desired_state: "{{ (( partition | first).nodes | map(attribute='name') | list )[:item.num_nodes] + desired_state | default([]) }}"
      when: partition | length > 0
      with_items: "{{ openhpc_slurm_partitions }}"

- hosts:
  - cluster_control
  become: yes
  tasks:
  - name: Get nodes in DRAINED state
    command: "sinfo --noheader --Node --format='%N' --states=DRAINED"
    register: drained_nodes_results
    changed_when: false
  - name: Get nodes in ALLOC,IDLE states
    command: "sinfo --noheader --Node --format='%N' --states=ALLOC,IDLE"
    register: resumed_nodes_results
    changed_when: false
  - set_fact:
      drained_nodes: "{{ drained_nodes_results.stdout_lines }}"
      resumed_nodes: "{{ resumed_nodes_results.stdout_lines }}"

- hosts:
  - cluster_batch
  become: yes
  vars:
    desired_state: "{{ hostvars['localhost']['desired_state'] }}"
    nodes_to_drain: "{{ groups['cluster_batch'] | difference(desired_state) | difference(hostvars[openhpc_slurm_control_host]['drained_nodes']) }}"
    nodes_to_resume: "{{ desired_state | difference(hostvars[openhpc_slurm_control_host]['resumed_nodes']) }}"
    openhpc_slurm_control_host: "{{ groups['cluster_control'] | first }}"
    openhpc_cluster_name: "{{ cluster_name }}"
    openhpc_enable:
      drain: "{{ inventory_hostname in nodes_to_drain }}"
      resume: "{{ inventory_hostname in nodes_to_resume }}"
  roles:
    - role: stackhpc.openhpc
  tasks:
    - debug: var=nodes_to_drain
    - debug: var=nodes_to_resume
