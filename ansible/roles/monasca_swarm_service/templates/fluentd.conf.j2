# Accept logs from Docker Fluentd log driver
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

<filter *.**>
  @type parser
  key_name log
  format /(?<Timestamp>\d{4}-\d{2}-\d{2}[T ]\d{2}:\d{2}:\d{2}[.,]\d{3,6}Z)\s+[-|]\s+(?<module>\S+)\s+[-|]\s+(?<level>\S+)\s+[-|]?\s+(?<thread>.*)\s+[-|]\s+(?<log>.*)/
  time_key Timestamp
  time_format %Y-%m-%dT%H:%M:%S.%NZ
</filter>

# Add a timestamp dimension with ms precision to all logs to record
# the event time. The event time is the time extracted from the log
# message in all cases where the time_key is set, and the time the
# record entered fluentd if no time_key is set logs.
# NOTE: ISO8601 is used to be compatible with the Monasca pipeline.
<filter *.**>
  @type record_transformer
  enable_ruby
  <record>
    timestamp ${time.strftime('%Y-%m-%dT%H:%M:%S.%3NZ')}
  </record>
</filter>

# Docker saves all logs under the 'log' field. The fluentd-monasca
# plugin assumes that they are saved under the 'message' field. Here
# we map the 'log' field to the 'message' field for all logs. If
# we do this directly in the first format filter, rather than here,
# the record_transformer filter fails with an error about the
# missing log field (Fluent v0.14).
<filter *.**>
  @type record_transformer
  enable_ruby true
  <record>
    message ${record["log"]}
    docker_tag ${tag}
  </record>
  remove_keys log
</filter>

<match *.**>
    @type copy
    <store>
       @type monasca
       keystone_url {{ monasca_swarm_service_keystone_uri }}
       monasca_log_api {{ monasca_swarm_service_log_api_uri }}
       monasca_log_api_version v3.0
       username {{ monasca_swarm_service_username }}
       password {{ monasca_swarm_service_password }}
       domain_id default
       project_name {{ monasca_swarm_service_project_name }}
    </store>
</match>
